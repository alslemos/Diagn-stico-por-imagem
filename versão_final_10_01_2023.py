# -*- coding: utf-8 -*-
"""Versão final 10/01/2023

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14fdXR5zdkWS5c7-wqnaoTrjQ4k5CaI9l
"""

import os
import cv2
import keras
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import sklearn.metrics as skm 
import matplotlib.pyplot as plt

from tqdm import tqdm
from random import randint
from sklearn.utils import shuffle
from sklearn.metrics import confusion_matrix
from tensorflow.keras.layers import LeakyReLU  #destaque para o leakyReLU
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.utils.vis_utils import plot_model

import warnings
warnings.simplefilter("ignore")

"""## Montando o Drive do Google e Escrevendo o caminho do Dataset"""

from google.colab import drive
drive.mount('/content/drive')
path = "/content/drive/MyDrive/6 Semestre/Diagnóstico/archive"

"""## Classes de Dados"""

class_names = ['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']

"""## Definindo Dados de Teste e Treinamento"""

X_treino = []
Y_treino = []

X_teste = []
Y_teste = []

image_size = 150

for i in class_names:

    folderPath = os.path.join('/content/drive/MyDrive/6 Semestre/Diagnóstico/archive/','Training',i)
    
    for j in tqdm(os.listdir(folderPath)):
        img = cv2.imread(os.path.join(folderPath,j))
        img = cv2.resize(img,(image_size, image_size))
        X_treino.append(img)
        Y_treino.append(i)
        
for i in class_names:
    folderPath = os.path.join('/content/drive/MyDrive/6 Semestre/Diagnóstico/archive/','Testing',i)
    for j in tqdm(os.listdir(folderPath)):
        img = cv2.imread(os.path.join(folderPath,j))
        img = cv2.resize(img,(image_size, image_size))
        X_teste.append(img)
        Y_teste.append(i)

X_treino = np.array(X_treino)
Y_treino = np.array(Y_treino)

X_teste = np.array(X_teste)
Y_teste = np.array(Y_teste)

"""## Dados Categóricos"""

Y_treino = np.unique(Y_treino, return_inverse=True)[1]
Y_teste = np.unique(Y_teste, return_inverse=True)[1]

"""## Redimensionando Imagens"""

X_treino = X_treino/255.0
X_teste = X_teste/255.0

"""## Plotando uma Imagem de cada Classe do Dataset"""

fig, ax = plt.subplots(1, 4, figsize = (15,15))

k = 0
for i in range(4):
  ax[i].axis('off')
  ax[i].imshow(X_treino[k])
  ax[i].set_title(class_names[Y_treino[k]])
  k += 850

plt.show()

"""## Validação dos Dados"""

X_treino, X_validacao, label_treino, label_validacao = train_test_split( X_treino, Y_treino, test_size=0.15, random_state=15)

"""## Otimização do Código"""

np.random.RandomState(10)
tf.random.set_seed(10)

"""## Construção do Modelo"""

def get_model():

    model = Sequential()

    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(150,150,3), padding='same'))
    model.add(MaxPooling2D((2, 2), padding='same'))
    model.add(Dropout(0.20))

    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
    model.add(Dropout(0.30))

    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))             
    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
    model.add(Dropout(0.40))

    model.add(Flatten())

    model.add(Dense(32, activation='relu'))
    model.add(Dropout(0.60))

    model.add(Dense(4, activation='softmax'))

    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])
    
    return model

model = get_model()

"""## Arquitetura do Modelo"""

model.summary()

"""## Testando Dados"""

history = model.fit(X_treino, label_treino, epochs=20, batch_size=64, validation_data = (X_validacao, label_validacao), verbose = 1)

"""## Gráfico referente ao treinamento e Validação"""

plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
plt.plot(history.history["loss"], label = "Treino")
plt.plot(history.history["val_loss"], label = "Validação")
plt.xlabel("Epocas")
plt.ylabel("Loss")
plt.legend();
plt.subplot(1,2,2)
plt.plot(history.history["accuracy"], label = "Treino")
plt.plot(history.history["val_accuracy"], label = "Validação")
plt.xlabel("Épocas")
plt.ylabel("Acurácia")
plt.legend();
fig.savefig('full_figure.png')

"""## Acurácia X Matriz de Confusão"""

predicted_classes = model.predict(X_teste)
predicted_classes = np.argmax(np.round(predicted_classes),axis=1)

print(classification_report(Y_teste, predicted_classes, 
  target_names=class_names))

# Gerando e apresentando a matriz de confusão

cmat = confusion_matrix(Y_teste, predicted_classes)
cm_df = pd.DataFrame(cmat) 

cmat_df = pd.DataFrame(cmat, index = class_names, columns = class_names)

plt.figure(figsize=(10,6))

sns.heatmap(cmat, annot = True, cmap = 'Greens', fmt = "d", cbar = False, xticklabels = class_names, yticklabels = class_names)

plt.title('Matriz de Confusão')
plt.show()